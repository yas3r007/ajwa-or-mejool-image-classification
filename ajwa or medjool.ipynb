{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b6c457e2-4add-47c5-a33e-a622c29f5485",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "642f3e46-56be-41d4-a3f5-4f8d270f4ea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d86b1547-ab26-4679-b832-1dff7fc33c60",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen=ImageDataGenerator(rescale=1/255,\n",
    "                                 shear_range=0.2,\n",
    "                                 zoom_range=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d4f034de-a5b4-4efe-98f3-ffeaf9d33734",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 160 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "training_set=train_datagen.flow_from_directory(\"datasets/training_set\",\n",
    "                                               target_size=(64,64),\n",
    "                                               class_mode=\"binary\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d764702f-2f5a-4d3c-b869-cafece977b39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Ajwa': 0, 'Medjool': 1}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_set.class_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "750b522f-7267-40ef-b5c0-7bdc52786a38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 40 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "test_datagen=ImageDataGenerator(rescale=1/255)\n",
    "\n",
    "test_set=test_datagen.flow_from_directory(\"datasets/test_set\",\n",
    "                                          target_size=(64,64),\n",
    "                                          class_mode=\"binary\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "003d8c17-e5d4-402c-9435-7aa2ea4db703",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "classifier=Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "510d5d70-83f7-4bde-be89-848e053027cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Yaser\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:99: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Conv2D\n",
    "classifier.add(Conv2D(input_shape=[64,64,3],\n",
    "                      filters=32,kernel_size=3,activation=\"relu\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1f080107-9a95-42cc-b128-44cb881bd9b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import MaxPooling2D\n",
    "classifier.add(MaxPooling2D(pool_size=2,strides=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "34651d03-bdd3-47cf-83be-fb834d82a77a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Flatten\n",
    "classifier.add(Flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "65608e4f-9d65-4289-bf18-504ba3942f56",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Dense\n",
    "\n",
    "classifier.add(Dense(units=128,activation =\"relu\"))\n",
    "classifier.add(Dense(units=1,activation=\"sigmoid\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8ac162dc-2e9f-4c6b-9c0c-428e71ff487a",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.compile(optimizer=\"adam\",loss=\"binary_crossentropy\",\n",
    "                   metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f7735cb3-b89d-4648-ab84-5c4c938ec62d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Yaser\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:120: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 3s/step - accuracy: 0.5497 - loss: 1.0744 - val_accuracy: 0.4750 - val_loss: 2.0455\n",
      "Epoch 2/25\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 2s/step - accuracy: 0.6935 - loss: 1.1876 - val_accuracy: 0.5500 - val_loss: 0.7006\n",
      "Epoch 3/25\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 2s/step - accuracy: 0.7122 - loss: 0.7250 - val_accuracy: 0.5750 - val_loss: 0.6349\n",
      "Epoch 4/25\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 2s/step - accuracy: 0.8126 - loss: 0.5152 - val_accuracy: 0.7750 - val_loss: 0.4977\n",
      "Epoch 5/25\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 2s/step - accuracy: 0.9324 - loss: 0.3824 - val_accuracy: 0.7250 - val_loss: 0.5191\n",
      "Epoch 6/25\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 2s/step - accuracy: 0.8760 - loss: 0.3712 - val_accuracy: 0.8500 - val_loss: 0.3756\n",
      "Epoch 7/25\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 2s/step - accuracy: 0.9248 - loss: 0.2976 - val_accuracy: 0.9500 - val_loss: 0.3111\n",
      "Epoch 8/25\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 2s/step - accuracy: 0.9760 - loss: 0.2072 - val_accuracy: 0.9750 - val_loss: 0.2191\n",
      "Epoch 9/25\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 2s/step - accuracy: 0.9606 - loss: 0.1899 - val_accuracy: 0.8750 - val_loss: 0.3061\n",
      "Epoch 10/25\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 2s/step - accuracy: 0.9135 - loss: 0.1953 - val_accuracy: 0.9750 - val_loss: 0.1525\n",
      "Epoch 11/25\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 2s/step - accuracy: 1.0000 - loss: 0.1028 - val_accuracy: 1.0000 - val_loss: 0.1172\n",
      "Epoch 12/25\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 2s/step - accuracy: 0.9871 - loss: 0.0769 - val_accuracy: 0.9750 - val_loss: 0.1232\n",
      "Epoch 13/25\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 2s/step - accuracy: 1.0000 - loss: 0.0685 - val_accuracy: 1.0000 - val_loss: 0.0792\n",
      "Epoch 14/25\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 2s/step - accuracy: 0.9966 - loss: 0.0534 - val_accuracy: 1.0000 - val_loss: 0.0725\n",
      "Epoch 15/25\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 2s/step - accuracy: 0.9979 - loss: 0.0491 - val_accuracy: 1.0000 - val_loss: 0.0648\n",
      "Epoch 16/25\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 2s/step - accuracy: 0.9979 - loss: 0.0524 - val_accuracy: 1.0000 - val_loss: 0.0864\n",
      "Epoch 17/25\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 2s/step - accuracy: 0.9923 - loss: 0.0484 - val_accuracy: 0.9750 - val_loss: 0.0822\n",
      "Epoch 18/25\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 2s/step - accuracy: 0.9966 - loss: 0.0516 - val_accuracy: 1.0000 - val_loss: 0.0439\n",
      "Epoch 19/25\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 2s/step - accuracy: 1.0000 - loss: 0.0371 - val_accuracy: 1.0000 - val_loss: 0.0400\n",
      "Epoch 20/25\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 2s/step - accuracy: 0.9966 - loss: 0.0314 - val_accuracy: 1.0000 - val_loss: 0.0361\n",
      "Epoch 21/25\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 2s/step - accuracy: 1.0000 - loss: 0.0287 - val_accuracy: 1.0000 - val_loss: 0.0340\n",
      "Epoch 22/25\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 2s/step - accuracy: 1.0000 - loss: 0.0205 - val_accuracy: 1.0000 - val_loss: 0.0301\n",
      "Epoch 23/25\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 2s/step - accuracy: 1.0000 - loss: 0.0260 - val_accuracy: 1.0000 - val_loss: 0.0237\n",
      "Epoch 24/25\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 2s/step - accuracy: 1.0000 - loss: 0.0182 - val_accuracy: 1.0000 - val_loss: 0.0209\n",
      "Epoch 25/25\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 2s/step - accuracy: 1.0000 - loss: 0.0182 - val_accuracy: 1.0000 - val_loss: 0.0225\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x230b41abda0>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.fit(x=training_set,validation_data=test_set,epochs=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cc0651f4-2c1f-4f7a-9353-98164a998572",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "48131cbc-7c61-4b93-a46f-2571c83bd523",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
      "ajwa\n"
     ]
    }
   ],
   "source": [
    "test_image=Image.open(\"datasets/single_prediction/ajwa_or_medjool_1.jpg\")\n",
    "test_image=test_image.resize((64,64))\n",
    "test_image=np.array(test_image)\n",
    "test_image=np.expand_dims(test_image,axis=0)\n",
    "\n",
    "result=classifier.predict(test_image)\n",
    "\n",
    "if result[0][0] ==1:\n",
    "    print(\"medjool\")\n",
    "else:\n",
    "    print(\"ajwa\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0000a706-d8ff-4cec-9744-feab218b7af3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
